# LLMSEC LITE SDK Configuration
# Copy this file to .env and fill in your values

# ===========================================
# API Keys (Required for full mode)
# ===========================================

# OpenAI API Key - required for hallucination detection
OPENAI_API_KEY=sk-your-openai-api-key-here

# Alternative: Use LLMSEC_API_KEY instead
# LLMSEC_API_KEY=sk-your-openai-api-key-here

# ===========================================
# LLM Model Configuration
# ===========================================

# Model for hallucination detection (LLM-as-judge)
# Options: gpt-4o-mini (default), gpt-4o, gpt-4-turbo, o3-mini
TRUSTGUARD_LLM=gpt-4o-mini

# API Base URL (for OpenAI-compatible APIs like Azure, local models)
# LLMSEC_API_BASE_URL=https://api.openai.com/v1

# ===========================================
# SDK Mode & Sensitivity
# ===========================================

# Operating mode: local (no API calls) or full (with hallucination detection)
LLMSEC_MODE=local

# Sensitivity: low, balanced (default), strict
LLMSEC_SENSITIVITY=balanced

# ===========================================
# Scanner Toggles
# ===========================================

LLMSEC_ENABLE_INJECTION=true
LLMSEC_ENABLE_SECRETS=true
LLMSEC_ENABLE_PII=true
LLMSEC_ENABLE_TOXICITY=true
LLMSEC_ENABLE_HALLUCINATION=true
LLMSEC_ENABLE_CODE_INJECTION=true

# ===========================================
# PII Settings
# ===========================================

LLMSEC_PII_REDACTION=true
# Redaction style: full ([REDACTED]), partial (***-**-1234), hash ([PII:a3f2...])
LLMSEC_PII_REDACTION_STYLE=full

# ===========================================
# Model Cache
# ===========================================

# Directory for ONNX model cache
LLMSEC_CACHE_DIR=~/.llmsec-lite

# ===========================================
# Logging
# ===========================================

LLMSEC_LOG_LEVEL=INFO
